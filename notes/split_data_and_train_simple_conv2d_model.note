; -*- mode: org; -*-
#+options: toc:2 num:nil
#+startup: overview
#+property: header-args:ein-python :results value :session http://127.0.0.1:8888/ein_server.ipynb
#+title: MNIST PyTorch ~conv2d~ model

* Overview
In this document we

- read the training data and plot it, checking labels
- reproducibly split the training data
- make simplest model and train it for one epoch on CPU and GPU
- test logging with [[https://mlflow.org/docs/latest/index.html][MLflow]]

*Note* Remember to eval ~ein:jupyter_server_start~ and "Open" the ~ein_server~
notebook.
   
* Packages
In this section, we import relevant Python packages from the ~conda~
environment pinned in ~/dev/conda_env.yaml~

Including ~kaggland.digrec~

#+NAME: f59a0093-75aa-4763-82fb-017d97ef4eb0
#+begin_src ein-python
  import pathlib

  import numpy as np
  import torch
  import torch.nn

  from sklearn.model_selection import StratifiedGroupKFold
  import matplotlib.pyplot as plt
  %matplotlib inline
  import mlflow

  # NOTE not included in /dev/conda_env.yaml
  import kaggland.digrec.data.load as load
#+end_src

* Data Split
Write and test util functions used to split the training data.

#+NAME: 3ecb7f09-2612-4c26-b61b-ede24bc9bd10
#+begin_src ein-python
  train_data = pathlib.Path.home() / "data" / "kaggle" / "digit-recognizer" / "train.csv"

  images, labels = load.load(str(train_data))

  def create_train_val_folds(size: int, num_folds: int, num_val_folds: int):
    cross_val_folds = StratifiedGroupKFold(n_splits=10, shuffle=True, random_state=0)

    indices_folds = []
    for _, idx_ith_fold in cross_val_folds.split(labels, y=labels, groups=labels):
        indices_folds.append(idx_ith_fold)

    num_train_folds = num_folds - num_val_folds
    train_indices = np.concatenate(indices_folds[:num_train_folds])
    val_folds = indices_folds[num_train_folds:]
    return train_indices, val_folds

  train_indices, val_folds = create_train_val_folds(len(labels), 10, 3)
  len(train_indices), len(val_folds), len(train_indices) + sum(len(el) for el in val_folds)
#+end_src

Are the indices in the folds all the indices?

#+NAME: 043ed403-f81e-48a6-a667-77dd01ea7046
#+begin_src ein-python
  indices_folds = np.concatenate((train_indices, *val_folds))
  (np.unique(indices_folds) == np.arange(len(indices_folds))).all()
#+end_src

** Sanity Check Plot
Check few images and labels.

#+NAME: de25ebd7-1db1-4ee6-9a02-bbc8c8851dce
#+begin_src ein-python
  num = 5
  fig, ax = plt.subplots(1, num, figsize=(num*4, 4))
  for i in range(num):
      ax[i].imshow(images[i], cmap="gray")
      ax[i].set(title=f"{labels[i]}")
  fig.show()
#+end_src

* Data loading
Using ~torch.utils.data.Dataset~ and ~torch.utils.data.Dataloader~.

#+NAME: 952c8b2c-8ebc-4b79-b342-927556729df5
#+begin_src ein-python
  import torch.utils.data
#+end_src

** MNISTDataset
*** Transforms

#+NAME: 23274bed-1466-4a56-b387-f66d7191cb10
#+begin_src ein-python
  data_transforms = {
      "train": [], # list of function operating on numpy arrays
      "test": [],
  }
#+end_src

*** Dataset
Some code from https://sebastianraschka.com/blog/2022/datapipes.html

#+NAME: 9881fc12-c0e2-4d6d-86f7-12f384bad034
#+begin_src ein-python
  class MNISTDataset(torch.utils.data.Dataset):
      def __init__(self, samples: np.ndarray, labels: np.ndarray, transforms=None):
          assert len(samples) == len(labels)

          self.samples = samples
          self.labels = labels
          self.transforms = transforms

      def __getitem__(self, index):
          sample = self.samples[index]

          if self.transforms is not None:
              for transform_fn in self.transforms:
                  image = transform_fn(image)

          return sample, self.labels[index]

      def __len__(self):
          return len(self.labels)

  train_samples = images[train_indices]
  train_labels = labels[train_indices]


  train_dataset = MNISTDataset(
      samples=train_samples,
      labels=train_labels,
      transforms=data_transforms["train"]
  )

  len(train_dataset), train_dataset[0][0].shape
#+end_src

#+NAME: 36dc770e-c9c4-4bf3-9ea8-19a1d23a81b5
#+begin_src ein-python
  torch.zeros(size=(5,))
#+end_src

** torch.utils.data.DataLoader
#+NAME: 40002dfd-9113-4bea-bf26-58d8d99b1e29
#+begin_src ein-python :results output
  torch.manual_seed(100)
  batch_size = 6
  dtype_samples = torch.uint8

  def collate_MNIST_mini_batch(batch):
      batched_samples = torch.zeros(size=(len(batch), *batch[0][0].shape), dtype=dtype_samples)
      batched_labels = torch.zeros(size=(len(batch),), dtype=torch.uint8)
      for idx in range(len(batch)):
          batched_samples[idx] = torch.from_numpy(batch[idx][0])
          batched_labels[idx] = int(batch[idx][1])
      return batched_samples, batched_labels

  train_loader = torch.utils.data.DataLoader(
      dataset=train_dataset,
      batch_size=batch_size,
      shuffle=True,
      drop_last=True,
      num_workers=1,
      collate_fn=collate_MNIST_mini_batch,
  )

  train_iter = iter(train_loader)

  for _ in range(5):
      batch = next(train_iter)
      print(len(batch), batch[0].shape, batch[1])
#+end_src

** Sanity check plot

#+NAME: a7a48af6-30a9-4478-bcaa-0add2513d5a5
#+begin_src ein-python
  num = batch_size
  fig, ax = plt.subplots(1, num, figsize=(num*4, 4))
  for i, batch in enumerate(train_loader):
      image = batch[0][0]
      label = batch[1][0]
      if i < num:
          ax[i].imshow(image, cmap="gray")
          ax[i].set(title=f"{label}")
      else:
          break
  fig.show()
#+end_src

* As-simple-as-possible model
