; -*- mode: org; -*-
#+options: toc:2 num:nil
#+startup: overview
#+property: header-args:ein-python :results value :session http://127.0.0.1:8888/ein_server.ipynb
#+title: MNIST PyTorch ~conv2d~ model

* Overview
In this document we

- read the training data and plot it, checking labels
- reproducibly split the training data
- make simplest model and train it for one epoch on CPU and GPU
- test logging with [[https://mlflow.org/docs/latest/index.html][MLflow]]

*Note* Remember to eval ~ein:jupyter_server_start~ and "Open" the ~ein_server~
notebook.
   
* Packages
In this section, we import relevant Python packages from the ~conda~
environment pinned in ~/dev/conda_env.yaml~

Including ~kaggland.digrec~

#+NAME: f59a0093-75aa-4763-82fb-017d97ef4eb0
#+begin_src ein-python
  import os
  import pathlib
  import subprocess
  import time

  import numpy as np
  import torch
  import torch.nn

  from omegaconf import OmegaConf as oc

  from sklearn.model_selection import StratifiedKFold
  import matplotlib.pyplot as plt
  %matplotlib inline
  import mlflow

  # NOTE not included in /dev/conda_env.yaml
  import kaggland.digrec.data.load as load
#+end_src

* Config
Using [[https://omegaconf.readthedocs.io/en/latest/][OmegaConf]] to create a config that can use the ~${other.field}~ syntax and
~OmegaConf.resolve()~ to interpolate configuration values.

#+NAME: 8c6d20ec-8b1a-43dc-9acc-8640cccc1f40
#+begin_src ein-python
  python_version = subprocess.run(
      ["python", "--version"],
      capture_output=True).stdout.decode("utf-8").replace("Python", "").strip()

  base_config = {
      "info" : {
          "python_version" : python_version,
          "numpy_version" : str(np.__version__),
          "torch_version" : str(torch.__version__),
      }
  }
  data_config = {
      "data": {
          "path_to_data" : pathlib.Path.home() / "data" / "kaggle" / "digit-recognizer" / "train.csv",
          "num_splits": 10,
          "num_val_splits": 3,
      }
  }

  model_config = {
      "model": {
          "resnet_blocks": {
              "resnet1": {"kernel_size": (3, 3), "init_fn": "kaiming"},
          },
      }
  }

  config = oc.merge(
      oc.create(base_config),
      oc.create(data_config),
      oc.create(model_config),
  )
  oc.resolve(config) 

  config, type(config), config.model.resnet_blocks
#+end_src

* Data Split
Write and test util functions used to split the training data.

#+NAME: 3ecb7f09-2612-4c26-b61b-ede24bc9bd10
#+begin_src ein-python :results output
  def prepare_data(path_to_data: pathlib.PosixPath):
    """Read and split the MNIST dataset."""

    assert isinstance(path_to_data, pathlib.PosixPath), f"{path_to_data=} needs to be a pathlib.Path"

    images, labels = load.load(path_to_data)

    train_indices, val_splits = make_train_val_splits(
      labels=labels,
      num_splits=10,
      num_val_splits=3,
      random_state=0
    )

    train_data = {"images": images[train_indices], "labels": labels[train_indices], "indices": train_indices}
    val_data = {idx: {"images": images[val_indices], "labels": labels[val_indices], "indices": val_indices}
                for idx, val_indices in enumerate(val_splits)}

    return train_data, val_data    

  def make_train_val_splits(labels: np.ndarray, num_splits: int, num_val_splits: int, random_state: int=0):
    """Return training/validation data splits using `StratifiedKFold`."""

    cross_val_splits = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=random_state)

    indices_splits = []
    for _, idx_ith_fold in cross_val_splits.split(labels, y=labels):
        indices_splits.append(idx_ith_fold)

    # get indices of train and validation splits
    num_train_splits = num_splits - num_val_splits
    train_indices = np.concatenate(indices_splits[:num_train_splits])
    val_splits = indices_splits[num_train_splits:]

    # shuffle indices in splits, setting random_seed
    np.random.seed(random_state)
    train_indices = train_indices[np.random.permutation(len(train_indices))]
    for idx, val_indices in enumerate(val_splits):
      val_splits[idx] = val_indices[np.random.permutation(len(val_indices))]

    return train_indices, val_splits

  train_data, val_data = prepare_data(config.data.path_to_data)
  train_images = train_data["images"]
  train_labels = train_data["labels"]

  print("unique train_labels:", np.unique(train_labels))

  for _, val_img_lab in val_data.items():
    val_labels = val_img_lab["labels"]
    print("unique val_labels:", np.unique(val_labels))
#+end_src

Are the indices in the splits all the indices?

#+NAME: 043ed403-f81e-48a6-a667-77dd01ea7046
#+begin_src ein-python
  train_indices = train_data["indices"]
  val_splits = tuple(value["indices"] for value in val_data.values())

  indices_splits = np.concatenate((train_indices, *val_splits))
  (np.unique(indices_splits) == np.arange(len(indices_splits))).all()
#+end_src

** Sanity Check Plot
Check few images and labels.

#+NAME: de25ebd7-1db1-4ee6-9a02-bbc8c8851dce
#+begin_src ein-python
  num = 5
  fig, ax = plt.subplots(1, num, figsize=(num*4, 4))
  for i in range(num):
      img = train_images[i]
      lab = train_labels[i]
      ax[i].imshow(img, cmap="gray")
      ax[i].set(title=f"{lab}")
  fig.show()
#+end_src

* Data loading with ~DataLoader~
Using ~torch.utils.data.Dataset~ and ~torch.utils.data.DataLoader~ for loading
mini-batches of ~torch.Tensor~

#+NAME: 952c8b2c-8ebc-4b79-b342-927556729df5
#+begin_src ein-python
  import torch.utils.data
#+end_src

** MNISTDataset
*** Transforms

#+NAME: 23274bed-1466-4a56-b387-f66d7191cb10
#+begin_src ein-python
  data_transforms = {
      "train": [], # list of function operating on numpy arrays
      "test": [],
  }
#+end_src

*** Dataset
Some code from https://sebastianraschka.com/blog/2022/datapipes.html

#+NAME: 9881fc12-c0e2-4d6d-86f7-12f384bad034
#+begin_src ein-python
  class MNISTDataset(torch.utils.data.Dataset):
      def __init__(self, samples: np.ndarray, labels: np.ndarray, transforms=None):
          assert len(samples) == len(labels)

          self.samples = samples
          self.labels = labels
          self.transforms = transforms

      def __getitem__(self, index):
          sample = self.samples[index]

          if self.transforms is not None:
              for transform_fn in self.transforms:
                  image = transform_fn(image)

          return sample, self.labels[index]

      def __len__(self):
          return len(self.labels)

  train_dataset = MNISTDataset(
      samples=train_images,
      labels=train_labels,
      transforms=data_transforms["train"]
  )

  len(train_dataset), train_dataset[0][0].shape
#+end_src

** torch.utils.data.DataLoader

#+NAME: 40002dfd-9113-4bea-bf26-58d8d99b1e29
#+begin_src ein-python :results output
  torch.manual_seed(100)
  batch_size = 8
  dtype_samples = torch.uint8

  def collate_MNIST_mini_batch(batch):
      batched_samples = torch.zeros(size=(len(batch), *batch[0][0].shape), dtype=dtype_samples)
      batched_labels = torch.zeros(size=(len(batch),), dtype=torch.uint8)
      for idx in range(len(batch)):
          batched_samples[idx] = torch.from_numpy(batch[idx][0])
          batched_labels[idx] = int(batch[idx][1])
      return batched_samples, batched_labels

  train_loader = torch.utils.data.DataLoader(
      dataset=train_dataset,
      batch_size=batch_size,
      shuffle=True,
      drop_last=True,
      num_workers=4,
      collate_fn=collate_MNIST_mini_batch,
  )

  train_iter = iter(train_loader)

  for _ in range(5):
      batch = next(train_iter)
      print(len(batch), batch[0].shape, batch[1])
#+end_src

** Sanity check plot

#+NAME: a7a48af6-30a9-4478-bcaa-0add2513d5a5
#+begin_src ein-python
  num = 5
  fig, ax = plt.subplots(1, num, figsize=(num*4, 4))
  for i, batch in enumerate(train_loader):
      image = batch[0][0]
      label = batch[1][0]
      if i < num:
          ax[i].imshow(image, cmap="gray")
          ax[i].set(title=f"{label}")
      else:
          break
  fig.show()
#+end_src

** Sanity check: time for one epoch ~DataLoader~

#+NAME: 179e8345-da5e-4676-b3e9-a8467c49a79b
#+begin_src ein-python :results output
  start_time = time.time()

  total = 0
  for batch in train_loader:
      images = batch[0]
      total += images[0][14, 10:12].sum()

  end_time = time.time()

  print(f"Elapsed time epoch: {end_time - start_time:.3f} seconds")
  print(f"Total: {total}")
#+end_src

* Other data loading method: ~DataPipe~ and ~DataLoader2~
Experimenting with and testing the performance of ~DataPipes~ in ~torchdata~.

#+NAME: 0ad50ee0-b595-497b-bb1a-b8d0ff9b7f59
#+begin_src ein-python
  import torchdata.dataloader2 as dataloader2
  from torchdata.datapipes.map import SequenceWrapper

  train_data, val_data = prepare_data(config.data.path_to_data)
  train_images = train_data["images"]
  train_labels = train_data["labels"]

  def train_transforms_dp_fn(img_lab):
      img, lab = img_lab[0], img_lab[1]
      img = img.astype(np.float32) / 255
      lab = lab.astype(np.int64)
      return img_lab

  train_dp = (
      SequenceWrapper(train_images)
      .zip(SequenceWrapper(train_labels))
      .shuffle()
      .set_seed(0)
      .sharding_filter()
      .map(train_transforms_dp_fn)
      .batch(8)
      .collate(collate_MNIST_mini_batch)
  )
#+end_src

View the ~DataPipe~ DAG (using ~graphviz~ which requires ~conda install -c
conda-forge python-graphviz~)

#+NAME: a05f3d2d-7ba5-4c74-80b5-ad2c4fb08d7d
#+begin_src ein-python
  # import torchdata.datapipes.utils as dputils
  # dp_graph = dputils.to_graph(train_dp)
  # dp_graph.view()
#+end_src

#+NAME: 615561a4-42c9-4c99-93c2-1b4609128681
#+begin_src ein-python :results output
  torch.manual_seed(100)
  batch_size = 8
  dtype_samples = torch.uint8
  rs = dataloader2.MultiProcessingReadingService(
      num_workers=4,
      worker_prefetch_cnt=0,
      main_prefetch_cnt=0
  )
  dp_train_loader = dataloader2.DataLoader2(datapipe=train_dp, reading_service=rs)
  dp_train_loader_iter = iter(train_loader)

  for _ in range(2):
      batch = next(dp_train_loader_iter)
      sample0 = batch[1]
      print(f"type(batch): {type(batch)}, l={len(batch)}")
      print(f"sample0: (dtype={sample0.dtype}, shape={sample0.shape})")
      print("---")
#+end_src

** Sanity check plot

#+NAME: a7a48af6-30a9-4478-bcaa-0add2513d5a5
#+begin_src ein-python
  num = 5

  fig, ax = plt.subplots(1, num, figsize=(num*4, 4))
  for i, batch in enumerate(dp_train_loader):
      image = batch[0][0]
      label = batch[1][0]
      if i < num:
          ax[i].imshow(image, cmap="gray")
          ax[i].set(title=f"{label}")
      else:
          break
  fig.show()
#+end_src

** Sanity check: ~DataLoader2~ returns same amounts of digits?
Get all ~DataPipe~ labels

#+NAME: 15243c93-0247-4e03-91d2-1d5fa1ff161b
#+begin_src ein-python :results output 
  dp_labels = torch.zeros(size=(len(train_labels),), dtype=torch.uint8)

  idx = 0
  for batch in dp_train_loader:
      for j, el in enumerate(batch[1]):
          dp_labels[idx] = el
          idx += 1
#+end_src

Performe check using ~np.unique~

#+NAME: 1a300a22-28ec-4b7c-ba7f-298381a7a668
#+begin_src ein-python :results output 
  u1, cnt1 = np.unique(dp_labels, return_counts=True)
  # u2, cnt2 = np.unique(labels, return_counts=True)
  u3, cnt3 = np.unique(train_labels, return_counts=True)

  print(f"DataPipe -> u1: {u1}, counts: {cnt1}")
  print(f"Input lab -> u3: {u3}, counts: {cnt3}")
#+end_src

** Sanity check: time for one epoch ~DataPipe~

#+NAME: 179e8345-da5e-4676-b3e9-a8467c49a79b
#+begin_src ein-python :results output
  start_time = time.time()

  total = 0
  for batch in dp_train_loader:
      images = batch[0]
      total += images[0][14, 10:12].sum()

  end_time = time.time()

  print(f"Elapsed time epoch: {end_time - start_time:.3f} seconds")
  print(f"Total: {total}")
#+end_src

** Conclusions of comparison between ~Dataset/DataLoader~ and ~DataPipe/DataLoader2~
- ~DataLoader2~ allows you to write less code and provides the same
  functionality
- ~DataLoader2~ provides more prefetching parameters
- ~DataLoader2~ provides more control on the worker processes used to load the
  data
- ~DataPipes~ allow to plot the preprocessing steps with a ~graphviz~ graph

* As-simple-as-possible model
Model

#+NAME: fdfea3c4-3556-4d93-90d1-702759d45754
#+begin_src ein-python
  import torch
  import torch.optim as optim
  import torch.nn as nn
  import torch.nn.functional as F

  class ConvModelV1(nn.Module):

      def __init__(self):
          super(ConvModelV1, self).__init__()
          self.conv1 = nn.Conv2d(1, 20, 5)
          self.conv2 = nn.Conv2d(20, 20, 5)

      def forward(self, x):
          x = F.relu(self.conv1(x))
          return F.relu(self.conv2(x))

  model = ConvModelV1()
  loss_fn = nn.CrossEntropyLoss()

  def training_loop(n_epochs, optimizer, model, train_loader, loss_fn):
      for epoch in range(1, n_epochs+1):
          for batch in train_loader:
              images = batch[0]
              target = batch[1]

              optimizer.zero_grad()

              output_model = model(images)
              loss = loss_fn(output_model, target)
              loss.backward()

              optimizer.step() # "learn"

              if (epoch % 500) == 0:
                  print(f"Epoch {epoch}, Loss {loss:.3f}")

  optimizer = optim.Adam(model.parameters(), lr=1e-1)
  training_loop(
      n_epochs=1,
      optimizer=optimizer,
      model=model,
      train_loader=dp_train_loader,
      loss_fn=loss_fn,
  )
#+end_src

