; -*- mode: org; -*-
#+options: toc:2 num:nil
#+startup: overview
#+property: header-args:ein-python :results value :session http://127.0.0.1:8888/ein_server.ipynb
#+title: MNIST PyTorch ~conv2d~ model

* Overview
In this document we

- read the training data and plot it, checking labels
- reproducibly split the training data
- make simplest model and train it for one epoch on CPU and GPU
- test logging with [[https://mlflow.org/docs/latest/index.html][MLflow]]

*Note* Remember to eval ~ein:jupyter_server_start~ and "Open" the ~ein_server~
notebook.
   
* Packages
In this section, we import relevant Python packages from the ~conda~
environment pinned in ~/dev/conda_env.yaml~

Including ~kaggland.digrec~

#+NAME: a028d7b1-d5d8-4f99-a77b-5228a716cd6c
#+begin_src ein-python
  import os
  import pathlib
  import subprocess
  import time

  from typing import Tuple
  from functools import partial

  import numpy as np
  import torch
  import torchdata.dataloader2 as dataloader2
  from torchdata.datapipes.map import SequenceWrapper
  import torch.nn as nn
  import torch.optim as optim

  from omegaconf import OmegaConf as oc
  from sklearn.model_selection import StratifiedKFold
  import matplotlib.pyplot as plt
  %matplotlib inline
  import mlflow

  # NOTE not included in /dev/conda_env.yaml
  import kaggland.digrec.data.load as load
#+end_src

* Config
Using [[https://omegaconf.readthedocs.io/en/latest/][OmegaConf]] to create a config that can use the ~${other.field}~ syntax and
~OmegaConf.resolve()~ to interpolate configuration values.

#+NAME: b6aa5b80-111b-4680-b785-96ce42024b34
#+begin_src ein-python
  python_version = subprocess.run(
      ["python", "--version"],
      capture_output=True).stdout.decode("utf-8").replace("Python", "").strip()

  base_config = {
      "info" : {
          "python_version" : python_version,
          "numpy_version" : str(np.__version__),
          "torch_version" : str(torch.__version__),
      },
      "use_cuda": True,
  }

  data_config = {
      "data": {
          "path_to_data" : pathlib.Path.home() / "data" / "kaggle" / "digit-recognizer" / "train.csv",
          "num_splits": 10,
          "num_val_splits": 3,
          "training": {
              "batch_size": 64,
              "num_workers": 2,
          },
          "validation": {
              "batch_size": 64,
              "num_workers": 2,
          },
      },
  }
#+end_src

#+NAME: 8c6d20ec-8b1a-43dc-9acc-8640cccc1f40
#+begin_src ein-python
  model_config = {
      "model": {
          "blocks": [
              {"name": "resnet1",
               "params": {
                   "in_channels": 1,
                   "out_channels": 64,
                   "kernel_size": (5, 5),
                   "padding": 2,
                   "conv_weight_init_fn": "kaiming_normal_"},
               },
              {"name": "resnet2",
               "params": {
                   "in_channels": 64,
                   "out_channels": 32,
                   "kernel_size": (3, 3),
                   "padding": 1,
                   "conv_weight_init_fn": "kaiming_normal_"},
               },
              {"name": "resnet3",
               "params": {
                   "in_channels": 32,
                   "out_channels": 16,
                   "kernel_size": (3, 3),
                   "padding": 1,
                   "conv_weight_init_fn": "kaiming_normal_"},
               },
              {"name": "resnet4",
               "params": {
                   "in_channels": 16,
                   "out_channels": "${model.num_out_channels}",
                   "kernel_size": (3, 3),
                   "padding": 1,
                   "conv_weight_init_fn": "kaiming_normal_"},
               },
          ],
          "num_out_channels": 10,
      }
  }

  config = oc.merge(
      oc.create(base_config),
      oc.create(data_config),
      oc.create(model_config),
  )
  oc.resolve(config) 

  config.data, config.model.blocks
#+end_src

* Data Split
Write and test util functions used to split the training data.

** Make split and prepare data

#+NAME: 3ecb7f09-2612-4c26-b61b-ede24bc9bd10
#+begin_src ein-python :results output
  def make_data(path_to_data: pathlib.PosixPath):
    """Read and split the MNIST dataset."""

    assert isinstance(path_to_data, pathlib.PosixPath), f"{path_to_data=} needs to be a pathlib.Path"

    images, labels = load.load(path_to_data)

    train_indices, val_splits = make_train_val_splits(
      labels=labels,
      num_splits=10,
      num_val_splits=3,
      random_state=0
    )

    train_data = {"images": images[train_indices], "labels": labels[train_indices], "indices": train_indices}
    val_data = {idx: {"images": images[val_indices], "labels": labels[val_indices], "indices": val_indices}
                for idx, val_indices in enumerate(val_splits)}

    return train_data, val_data    

  def make_train_val_splits(labels: np.ndarray, num_splits: int, num_val_splits: int, random_state: int=0):
    """Return training/validation data splits using `StratifiedKFold`."""

    cross_val_splits = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=random_state)

    indices_splits = []
    for _, idx_ith_fold in cross_val_splits.split(labels, y=labels):
        indices_splits.append(idx_ith_fold)

    # get indices of train and validation splits
    num_train_splits = num_splits - num_val_splits
    train_indices = np.concatenate(indices_splits[:num_train_splits])
    val_splits = indices_splits[num_train_splits:]

    # shuffle indices in splits, setting random_seed
    np.random.seed(random_state)
    train_indices = train_indices[np.random.permutation(len(train_indices))]
    for idx, val_indices in enumerate(val_splits):
      val_splits[idx] = val_indices[np.random.permutation(len(val_indices))]

    return train_indices, val_splits

  train_data, val_data = make_data(config.data.path_to_data)
  train_images = train_data["images"]
  train_labels = train_data["labels"]

  print("unique train_labels:", np.unique(train_labels))

  for _, val_img_lab in val_data.items():
    val_labels = val_img_lab["labels"]
    print("unique val_labels:", np.unique(val_labels))
#+end_src

Are the indices in the splits all the indices?

#+NAME: 043ed403-f81e-48a6-a667-77dd01ea7046
#+begin_src ein-python
  train_indices = train_data["indices"]
  val_splits = tuple(value["indices"] for value in val_data.values())

  indices_splits = np.concatenate((train_indices, *val_splits))
  (np.unique(indices_splits) == np.arange(len(indices_splits))).all()
#+end_src

** Util function: compute ~train_images~ mean and standard deviation

#+NAME: d2566e7c-1efa-4026-adf5-1c952d36aca2
#+begin_src ein-python :results output
  def compute_mean_std(train_images: np.ndarray, np_type=np.float32) -> Tuple[np.ndarray, np.ndarray]:
      mean_train_images = np.mean(train_images).astype(np_type)
      std_train_images = np.std(train_images).astype(np_type)
      return mean_train_images, std_train_images
#+end_src

** Sanity Check Plots
Check few images and labels.

#+NAME: de25ebd7-1db1-4ee6-9a02-bbc8c8851dce
#+begin_src ein-python
  num = 5
  fig, ax = plt.subplots(1, num, figsize=(num*4, 4))
  for i in range(num):
      img = train_images[i]
      lab = train_labels[i]
      ax[i].imshow(img, cmap="gray")
      ax[i].set(title=f"{lab}")
  fig.show()
#+end_src

#+NAME: f0d06379-0215-4111-af4c-c81f1b62ae37
#+begin_src ein-python
  num = 12
  val_images = val_data[0]["images"]
  val_labels = val_data[0]["labels"]
  fig, ax = plt.subplots(1, num, figsize=(num*2, 2))
  for i in range(num):
      img = val_images[i]
      lab = val_labels[i]
      ax[i].imshow(img, cmap="gray")
      ax[i].set(title=f"{lab}")
  fig.show()
#+end_src

* Data loading with ~DataLoader~
Using ~torch.utils.data.Dataset~ and ~torch.utils.data.DataLoader~ for loading
mini-batches of ~torch.Tensor~

#+NAME: 952c8b2c-8ebc-4b79-b342-927556729df5
#+begin_src ein-python
  import torch.utils.data
#+end_src

** MNISTDataset
*** Transforms

#+NAME: 23274bed-1466-4a56-b387-f66d7191cb10
#+begin_src ein-python
  data_transforms = {
      "train": [], # list of function operating on numpy arrays
      "test": [],
  }
#+end_src

*** Dataset
Some code from https://sebastianraschka.com/blog/2022/datapipes.html

#+NAME: 9881fc12-c0e2-4d6d-86f7-12f384bad034
#+begin_src ein-python
  class MNISTDataset(torch.utils.data.Dataset):
      def __init__(self, samples: np.ndarray, labels: np.ndarray, transforms=None):
          assert len(samples) == len(labels)

          self.samples = samples
          self.labels = labels
          self.transforms = transforms

      def __getitem__(self, index):
          sample = self.samples[index]

          if self.transforms is not None:
              for transform_fn in self.transforms:
                  image = transform_fn(image)

          return sample, self.labels[index]

      def __len__(self):
          return len(self.labels)

  train_dataset = MNISTDataset(
      samples=train_images,
      labels=train_labels,
      transforms=data_transforms["train"]
  )

  len(train_dataset), train_dataset[0][0].shape
#+end_src

** torch.utils.data.DataLoader

#+NAME: 40002dfd-9113-4bea-bf26-58d8d99b1e29
#+begin_src ein-python :results output
  torch.manual_seed(100)
  batch_size = 8
  dtype_samples = torch.uint8

  def collate_MNIST_mini_batch(batch):
      batched_samples = torch.zeros(size=(len(batch), *batch[0][0].shape), dtype=dtype_samples)
      batched_labels = torch.zeros(size=(len(batch),), dtype=torch.uint8)
      for idx in range(len(batch)):
          batched_samples[idx] = torch.from_numpy(batch[idx][0])
          batched_labels[idx] = int(batch[idx][1])
      return batched_samples, batched_labels

  train_loader = torch.utils.data.DataLoader(
      dataset=train_dataset,
      batch_size=batch_size,
      shuffle=True,
      drop_last=True,
      num_workers=4,
      collate_fn=collate_MNIST_mini_batch,
  )

  train_iter = iter(train_loader)

  for _ in range(5):
      batch = next(train_iter)
      print(len(batch), batch[0].shape, batch[1])
#+end_src

** Sanity check plot

#+NAME: a7a48af6-30a9-4478-bcaa-0add2513d5a5
#+begin_src ein-python
  num = 5
  fig, ax = plt.subplots(1, num, figsize=(num*4, 4))
  for i, batch in enumerate(train_loader):
      image = batch[0][0]
      label = batch[1][0]
      if i < num:
          ax[i].imshow(image, cmap="gray")
          ax[i].set(title=f"{label}")
      else:
          break
  fig.show()
#+end_src

** Sanity check: time for one epoch ~DataLoader~

#+NAME: 179e8345-da5e-4676-b3e9-a8467c49a79b
#+begin_src ein-python :results output
  start_time = time.time()

  total = 0
  for batch in train_loader:
      images = batch[0]
      total += images[0][14, 10:12].sum()

  end_time = time.time()

  print(f"Elapsed time epoch: {end_time - start_time:.3f} seconds")
  print(f"Total: {total}")
#+end_src

* Other data loading method: ~DataPipe~ and ~DataLoader2~
Experimenting with and testing the performance of ~DataPipes~ in ~torchdata~.

** Preprocessing transforms

#+NAME: eceb860a-e657-46d6-be6f-5fbb0544b212
#+begin_src ein-python
  def prepro_normalize_images(image: np.ndarray, mean_train_images: float, std_train_images: float) -> np.ndarray:
      normalized_image = (image.astype(np.float32) - mean_train_images) / std_train_images
      return normalized_image

  def prepro_transforms_fn(image_label: Tuple[np.ndarray, np.ndarray], mean_train_images: float, std_train_images: float) -> Tuple[np.ndarray, np.ndarray]:
      image, label = image_label[0], image_label[1]
      image = prepro_normalize_images(image, mean_train_images, std_train_images)
      return image, label.astype(np.int64)
#+end_src

** Augmentation transforms

#+NAME: cf829484-a80e-4e77-a460-ad41c5df79ab
#+begin_src ein-python
  pass
#+end_src

** Collate function

#+NAME: d3e5d2dc-f7c5-4019-9a1b-232ea46985af
#+begin_src ein-python
  def collate_MNIST_mini_batch(many_images_labels):
      batched_samples = torch.zeros(size=(len(many_images_labels), 1, *many_images_labels[0][0].shape),
                                    dtype=torch.float32)
      batched_labels = torch.zeros(size=(len(many_images_labels),),
                                   dtype=torch.int64)

      for idx, (image, label) in enumerate(many_images_labels):
          batched_samples[idx, 0] = torch.from_numpy(image)
          batched_labels[idx] = int(label)

      return batched_samples.requires_grad_(True), batched_labels
#+end_src

** Training/Validation DataPipes

#+NAME: 0ad50ee0-b595-497b-bb1a-b8d0ff9b7f59
#+begin_src ein-python
  def make_MNIST_training_datapipe(train_data, data_config, random_state: int=100):
      """Make a datapipe for training data."""

      torch.manual_seed(random_state)

      train_images = train_data["images"]
      train_labels = train_data["labels"]
      mean_train_images, std_train_images = compute_mean_std(train_images)

      training_datapipe = (
          SequenceWrapper(train_images)
          .zip(SequenceWrapper(train_labels))
          .shuffle()
          .set_seed(0)
          .sharding_filter()
          .map(partial(prepro_transforms_fn,
                       mean_train_images=mean_train_images,
                       std_train_images=std_train_images))
          .batch(data_config.training.batch_size)
          .collate(collate_MNIST_mini_batch)
      )

      return training_datapipe

  def make_MNIST_validation_datapipe(train_data, val_data, data_config, idx_val_split: int=0, random_state: int=100):
      """Make DataPipe for validation data, using the validation split at index `idx_val_split`."""
    
      torch.manual_seed(random_state)

      train_images = train_data["images"]
      train_labels = train_data["labels"]
      val_images = val_data[idx_val_split]["images"]
      val_labels = val_data[idx_val_split]["labels"]
      mean_train_images, std_train_images = compute_mean_std(train_images)

      validation_datapipe = (
          SequenceWrapper(val_images)
          .zip(SequenceWrapper(val_labels))
          .shuffle()
          .set_seed(0)
          .sharding_filter()
          .map(partial(prepro_transforms_fn,
                       mean_train_images=mean_train_images,
                       std_train_images=std_train_images))
          .batch(data_config.validation.batch_size)
          .collate(collate_MNIST_mini_batch)
      )

      return validation_datapipe

  def make_dataloader2(datapipe, num_workers: int=1):
      """Make a DataLoader2 using a DataPipe."""

      reading_service = dataloader2.MultiProcessingReadingService(
          num_workers=num_workers,
          worker_prefetch_cnt=0,
          main_prefetch_cnt=0
      )

      loader = dataloader2.DataLoader2(datapipe=datapipe, reading_service=reading_service)

      return loader

  train_data, val_data = make_data(config.data.path_to_data)
  train_dp = make_MNIST_training_datapipe(train_data, config.data, random_state=100)
  val0_dp = make_MNIST_validation_datapipe(train_data, val_data=val_data, idx_val_split=0, data_config=config.data, random_state=100)
  train_loader = make_dataloader2(train_dp, num_workers=config.data.training.num_workers)
  val0_loader = make_dataloader2(val0_dp, num_workers=config.data.validation.num_workers)
#+end_src

*** DAG training DataPipe
View the ~DataPipe~ DAG (using ~graphviz~ which requires ~conda install -c
conda-forge python-graphviz~)

#+NAME: a05f3d2d-7ba5-4c74-80b5-ad2c4fb08d7d
#+begin_src ein-python
  import torchdata.datapipes.utils as dputils
  dp_graph = dputils.to_graph(train_dp)
  # dp_graph.view()
#+end_src

*** Testing training DataLoader2

#+NAME: 615561a4-42c9-4c99-93c2-1b4609128681
#+begin_src ein-python :results output
  train_data, val_data = make_data(config.data.path_to_data)
  train_dp = make_MNIST_training_datapipe(train_data, config.data, random_state=100)
  val0_dp = make_MNIST_validation_datapipe(train_data, val_data=val_data, idx_val_split=0, data_config=config.data, random_state=100)
  train_loader = make_dataloader2(train_dp, num_workers=config.data.training.num_workers)
  val0_loader = make_dataloader2(val0_dp, num_workers=config.data.validation.num_workers)

  dp_train_loader_iter = iter(train_loader)

  for _ in range(2):
      batch = next(dp_train_loader_iter)
      images = batch[0]
      labels = batch[1]
      print(f"type(batch): {type(batch)}, l={len(batch)}")
      print(f"images: (dtype={images.dtype}, shape={images.shape}, mean={images.mean():.3f})")
      print(f"labels: (dtype={labels.dtype}, shape={labels.shape})")
      print("---")
#+end_src

*** Sanity check plots

#+NAME: a7a48af6-30a9-4478-bcaa-0add2513d5a5
#+begin_src ein-python
  num = 5

  fig, ax = plt.subplots(1, num, figsize=(num*4, 4))
  for i, batch in enumerate(train_loader):
      image = batch[0][0][0].detach().numpy()
      label = batch[1][0]
      if i < num:
          ax[i].imshow(image, cmap="gray")
          ax[i].set(title=f"{label}, {image.sum():.3f}, {image.dtype}, {image.mean():.3f}")
      else:
          break
  fig.show()
#+end_src

#+NAME: 8c3942b7-a055-4a1d-83e2-03f18d11bf6a
#+begin_src ein-python
  num = 5

  fig, ax = plt.subplots(1, num, figsize=(num*4, 4))
  for i, batch in enumerate(val0_loader):
      image = batch[0][0][0].detach().numpy()
      label = batch[1][0]
      if i < num:
          ax[i].imshow(image, cmap="gray")
          ax[i].set(title=f"{label}, {image.sum():.3f}, {image.dtype}, {image.mean():.3f}")
      else:
          break
  fig.show()
#+end_src

*** Sanity check: ~DataLoader2~ returns same amounts of digits?
Get all ~DataPipe~ labels

#+NAME: 15243c93-0247-4e03-91d2-1d5fa1ff161b
#+begin_src ein-python :results output 
  dp_labels = torch.zeros(size=(len(train_labels),), dtype=torch.uint8)

  idx = 0
  for batch in dp_train_loader:
      for j, el in enumerate(batch[1]):
          dp_labels[idx] = el
          idx += 1
#+end_src

Performe check using ~np.unique~

#+NAME: 1a300a22-28ec-4b7c-ba7f-298381a7a668
#+begin_src ein-python :results output 
  u1, cnt1 = np.unique(dp_labels, return_counts=True)
  # u2, cnt2 = np.unique(labels, return_counts=True)
  u3, cnt3 = np.unique(train_labels, return_counts=True)

  print(f"DataPipe -> u1: {u1}, counts: {cnt1}")
  print(f"Input lab -> u3: {u3}, counts: {cnt3}")
#+end_src

*** Sanity check: time for one epoch ~DataPipe~

#+NAME: 179e8345-da5e-4676-b3e9-a8467c49a79b
#+begin_src ein-python :results output
  start_time = time.time()

  total = 0
  for batch in dp_train_loader:
      images = batch[0][0]
      total += images[0][14, 10:12].sum()

  end_time = time.time()

  print(f"Elapsed time epoch: {end_time - start_time:.3f} seconds")
  print(f"Total: {total}")
#+end_src

*** Conclusions of comparison between ~Dataset/DataLoader~ and ~DataPipe/DataLoader2~
- ~DataLoader2~ allows you to write less code and provides the same
  functionality
- ~DataLoader2~ provides more prefetching parameters
- ~DataLoader2~ provides more control on the worker processes used to load the
  data
- ~DataPipes~ allow to plot the preprocessing steps with a ~graphviz~ graph

* As-simple-as-possible model
** Configurable ResNet block

#+NAME: 304f701f-25ba-4a4a-8674-3bf575a9f5a3
#+begin_src ein-python
  class ResNetBlock(nn.Module):
      def __init__(self, resnet_block_config):
          super(ResNetBlock, self).__init__()

          self.conv = nn.Conv2d(
              in_channels=resnet_block_config.in_channels,
              out_channels=resnet_block_config.out_channels,
              kernel_size=resnet_block_config.kernel_size,
              padding=resnet_block_config.padding,
              bias=False
          )
          self.conv_1x1 = nn.Conv2d(
                in_channels=resnet_block_config.in_channels,
                out_channels=resnet_block_config.out_channels,
                kernel_size=1,
                padding=0,
                bias=False
            )
          self.batch_norm = nn.BatchNorm2d(
              num_features=resnet_block_config.out_channels
          )
          self.relu = nn.ReLU()

          conv_weight_init_fn = getattr(torch.nn.init, resnet_block_config.conv_weight_init_fn)
          conv_weight_init_fn(self.conv.weight, nonlinearity="relu")
          torch.nn.init.constant_(self.batch_norm.weight, 0.5)
          torch.nn.init.zeros_(self.batch_norm.bias)

      def forward(self, x):
          out = self.conv(x)
          out_1x1 = self.conv_1x1(x)
          out = self.batch_norm(out)
          out = self.relu(out)
          return out + out_1x1
#+end_src

** Model
Simplest model to check that everything is working.

#+NAME: 2df2f987-bd8a-4e0a-9d94-fe74c0e7bbbe
#+begin_src ein-python
  class Conv2dModelV1(nn.Module):
      def __init__(self, model_config):
          super(Conv2dModelV1, self).__init__()
          self.blocks = nn.ModuleDict([
              (block_config["name"], ResNetBlock(block_config["params"]))
              for block_config in model_config.blocks
          ])
          self.num_out_channels = model_config.num_out_channels
          self.head = nn.ModuleDict([
              ("linear_head", nn.Linear(28 * 28 * self.num_out_channels, self.num_out_channels)),
              ("batch_norm_head", nn.BatchNorm1d(num_features=10)),
              ("relu_head", nn.ReLU()),
          ])

      def forward(self, x):
          for block in self.blocks.values():
              x = block(x)

          x = x.view(x.size(0), -1)
          for block in self.head.values():
              x = block(x)

          return x

  model = Conv2dModelV1(config.model)
  # opt_model = torch.compile(model)
  "num trainable params:", sum(p.numel() for p in model.parameters() if p.requires_grad)
#+end_src

** Loss function and optimizer

#+NAME: dc5e8950-b90a-4749-9200-4c73be794f46
#+begin_src ein-python
  loss_fn = nn.CrossEntropyLoss()
  optimizer = optim.Adam(model.parameters(), lr=1e-1)
#+end_src

** TODO Training loop main function

#+NAME: fdfea3c4-3556-4d93-90d1-702759d45754
#+begin_src ein-python
  def training_loop(n_epochs, optimizer, model, train_loader, val_loader, loss_fn):
      """Training loop for MNIST classification task."""

      model.cuda()
      use_cuda = config.use_cuda

      for epoch in range(1, n_epochs+1):
          print("Training: ", end="")
          model.train(True)

          epoch_start_time = time.time()
          for idx_batch, batch in enumerate(train_loader):
              samples, targets = batch[0], batch[1]
              if use_cuda:
                  samples = samples.to(device="cuda")
                  targets = targets.to(device="cuda")

              optimizer.zero_grad()
              output_model = model(samples)
              loss = loss_fn(output_model, targets)
              loss.backward()
              optimizer.step()

              if idx_batch % 200 == 0:
                  print(".", end="", flush=True)
          print()

          print("Validation: ", end="")
          model.train(False)
          with torch.inference_mode():
              val_results_current_epoch = {"correct": 0, "total": 0}
              for idx_batch, batch in enumerate(val_loader):
                  samples, targets = batch[0], batch[1]
                  if use_cuda:
                      samples = samples.cuda()

                  output_model = model(samples)
                  model_predictions = torch.argmax(output_model, dim=1)
                
                  if use_cuda:
                      model_predictions = model_predictions.to(device="cpu").numpy()
                  expected_predictions = targets.numpy()
                
                  num_correct_predictions = (model_predictions == expected_predictions).sum()
                  val_results_current_epoch["correct"] += num_correct_predictions
                  val_results_current_epoch["total"] += len(expected_predictions)

                  if idx_batch % 200 == 0:
                      print(".", end="", flush=True)
          print()
          # ---
          epoch_end_time = time.time()
          print(f" --> Epoch {epoch}")
          print(f"Final training loss: {loss:.3f}")
          print(f"Validation correct predictions: {100*(val_results_current_epoch['correct'] / val_results_current_epoch['total']):.2f}%")
          print(f"Time: {epoch_end_time - epoch_start_time:.2f} seconds")
          print("-"*60)

#+end_src

#+NAME: 045e6d9b-7f72-4676-adc8-8b2ccbc573a7
#+begin_src ein-python :results output
  train_data, val_data = make_data(config.data.path_to_data)
  train_dp = make_MNIST_training_datapipe(train_data, config.data, random_state=100)
  val0_dp = make_MNIST_validation_datapipe(train_data, val_data=val_data, idx_val_split=0, data_config=config.data, random_state=100)
  train_loader = make_dataloader2(train_dp, num_workers=config.data.training.num_workers)
  val0_loader = make_dataloader2(val0_dp, num_workers=config.data.validation.num_workers)

  training_loop(
      n_epochs=1,
      optimizer=optimizer,
      model=model,
      train_loader=train_loader,
      val_loader=val0_loader,
      loss_fn=loss_fn,
  )
#+end_src
